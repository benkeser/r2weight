---
title: "r2weight"
author: "David Benkeser"
date: "August 22, 2016"
output: md_document
---

## Installation
The package can be installed directly from GitHub as follows:
```{r}
# need the devtools package
library("devtools")

# install from GitHub
install_github("benkeser/r2weight")
```

## Use
Here we provide a few examples of simple calls to the `r2weight` function. The
function is designed to learn the optimal weighted combination of outcomes that
can be predicted using a given set of variables. The `r2weight` function relies
on initial fits from the `CV.SuperLearner` function from the `SuperLearner` R
package available on CRAN. This demonstration will assume that the user is 
familiar with executing calls to `CV.SuperLearner`. We refer readers to the 
`SuperLearner` package documentation for additional information. 

Suppose we have `X`, a `data.frame` of three variables that we would like to use to predict the value of two related outcomes `Y1` and `Y2`:
```{r}
set.seed(1234)
# simulate a data.frame
X <- data.frame(x1 = runif(100, 0, 1),
                x2 = rnorm(100, 0, 1), 
                x3 = rbinom(100, 1, 0.5))

Y1 <- rnorm(100,mean=X$x1 + X$x2 + X$x3,sd=1)
Y2 <- rnorm(100,mean=X$x1 + X$x2 + X$x3,sd=2)
```
The two outcomes are related to `X` in the same way; however, `Y2` is more 
variable. We could use the function `SuperLearner` to perform cross-validaiton-based ensemble machine learning of the optimal prediction 
function for predicting `Y1` from `X` and for predicting `Y2` from `X`. The 
function `CV.SuperLearner` provides a means of assessing the performance of 
these predictions. In particular, `CV.SuperLearner` uses V-fold cross-validation
to evaluate the performance of `SuperLearner` for predicting the outcomes
separately. The function `r2weight` uses the fits from `CV.SuperLearner` to 
determine the optimal way of weighting the responses `Y1` and `Y2` such that
the predictive power (as measured by cross-validated $R^2$) is maximized. 

To apply the function `r2weight` requires several specific steps when executing 
the call to `CV.SuperLearner`. We must set the options `returnAll = TRUE` 
(default) and `control$saveFitLibrary = TRUE` (not default). Furthermore, we 
must ensure that the splits used in the outer V-fold cross-validation step are 
the same. This can be achieved by setting the same seed immediately before 
each call to `CV.SuperLearner`. We illustrate below using a simple example: 
```{r cvslfits, cache=TRUE}
# set a seed
set.seed(1234)
# execute call to CV.SuperLearner for predicting Y1
cvsl1 <- CV.SuperLearner(
    Y=Y1, # outcome = Y1
    X=X, # prediction frame
    SL.library = c("SL.glm","SL.step","SL.mean"), # simple library
    control=list(saveFitLibrary = TRUE), # needed for r2weight
    saveAll = TRUE # not needed because it's default option, 
                   # but include for clarity
)

# set the same seed to ensure same sample split
set.seed(1234)
# execute call to CV.SuperLearner for predicting Y2
cvsl2 <- CV.SuperLearner(
    Y=Y2, # outcome = Y2
    X=X, # prediction frame
    SL.library = c("SL.glm","SL.step","SL.mean"), # simple library
    control=list(saveFitLibrary = TRUE), # needed for r2weight
    saveAll = TRUE # not needed because it's default option, 
                   # but include for clarity
)
```

We can now execute a call to `r2weight` using these objects to obtain the 
estimated cross-validated $R^2$ for the optimally combined outcome: 
```{r}
r2Fit <- r2weight(cvslList = list(cvsl1, cvsl2), X=X)
r2Fit
```




